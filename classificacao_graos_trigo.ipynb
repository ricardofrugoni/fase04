{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Da Terra ao Código: Automatizando a Classificação de Grãos com Machine Learning\n",
        "\n",
        "## Projeto de Classificação de Variedades de Trigo usando CRISP-DM\n",
        "\n",
        "Este projeto aplica a metodologia CRISP-DM para desenvolver modelos de aprendizado de máquina que classificam variedades de grãos de trigo com base em suas características físicas.\n",
        "\n",
        "**Dataset:** Seeds Dataset (UCI Machine Learning Repository)\n",
        "**Variedades:** Kama (1), Rosa (2), Canadian (3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuração de visualização\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Entendimento do Negócio (Business Understanding)\n",
        "\n",
        "### Objetivo\n",
        "Desenvolver um modelo de Machine Learning para automatizar a classificação de variedades de grãos de trigo, substituindo o processo manual realizado por especialistas em cooperativas agrícolas.\n",
        "\n",
        "### Benefícios Esperados\n",
        "- Aumento da eficiência no processo de classificação\n",
        "- Redução de erros humanos\n",
        "- Padronização do processo de classificação\n",
        "- Economia de tempo e recursos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Entendimento dos Dados (Data Understanding)\n",
        "\n",
        "### 2.1. Carregamento e Exploração Inicial dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento do dataset\n",
        "# O dataset não possui cabeçalho, então definimos os nomes das colunas manualmente\n",
        "colunas = ['Area', 'Perimetro', 'Compacidade', 'Comprimento_Nucleo', \n",
        "           'Largura_Nucleo', 'Coeficiente_Assimetria', 'Comprimento_Sulco_Nucleo', 'Variedade']\n",
        "\n",
        "df = pd.read_csv('data/seeds_dataset.txt', sep='\\t', header=None, names=colunas)\n",
        "\n",
        "# Exibindo as primeiras linhas\n",
        "print(\"Primeiras 10 linhas do dataset:\")\n",
        "print(df.head(10))\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Informações gerais sobre o dataset\n",
        "print(\"Informações do Dataset:\")\n",
        "print(f\"Formato: {df.shape}\")\n",
        "print(f\"Número de amostras: {df.shape[0]}\")\n",
        "print(f\"Número de características: {df.shape[1] - 1}\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Verificando tipos de dados\n",
        "print(\"Tipos de dados:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Verificando valores ausentes\n",
        "print(\"Valores ausentes por coluna:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Distribuição das classes\n",
        "print(\"Distribuição das variedades:\")\n",
        "print(df['Variedade'].value_counts().sort_index())\n",
        "print(\"\\n\")\n",
        "print(\"Mapeamento:\")\n",
        "print(\"1 = Kama\")\n",
        "print(\"2 = Rosa\")\n",
        "print(\"3 = Canadian\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Estatísticas Descritivas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estatísticas descritivas para todas as características\n",
        "print(\"Estatísticas Descritivas:\")\n",
        "print(\"=\"*80)\n",
        "print(df.describe())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Estatísticas descritivas por variedade\n",
        "print(\"Estatísticas Descritivas por Variedade:\")\n",
        "print(\"=\"*80)\n",
        "for variedade in sorted(df['Variedade'].unique()):\n",
        "    nome_variedade = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}[variedade]\n",
        "    print(f\"\\n{nome_variedade} (Variedade {variedade}):\")\n",
        "    print(df[df['Variedade'] == variedade].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Visualizações Exploratórias\n",
        "\n",
        "#### 2.3.1. Histogramas das Características\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogramas para cada característica\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "fig.suptitle('Distribuição das Características', fontsize=16, fontweight='bold')\n",
        "\n",
        "caracteristicas = df.columns[:-1]  # Todas exceto a coluna 'Variedade'\n",
        "\n",
        "for idx, caracteristica in enumerate(caracteristicas):\n",
        "    row = idx // 4\n",
        "    col = idx % 4\n",
        "    axes[row, col].hist(df[caracteristica], bins=20, edgecolor='black', alpha=0.7)\n",
        "    axes[row, col].set_title(f'Distribuição de {caracteristica}', fontweight='bold')\n",
        "    axes[row, col].set_xlabel(caracteristica)\n",
        "    axes[row, col].set_ylabel('Frequência')\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "# Remover subplot vazio\n",
        "axes[1, 3].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.2. Boxplots das Características por Variedade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boxplots para cada característica separado por variedade\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "fig.suptitle('Distribuição das Características por Variedade', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Mapear números para nomes\n",
        "df_viz = df.copy()\n",
        "df_viz['Variedade_Nome'] = df_viz['Variedade'].map({1: 'Kama', 2: 'Rosa', 3: 'Canadian'})\n",
        "\n",
        "for idx, caracteristica in enumerate(caracteristicas):\n",
        "    row = idx // 4\n",
        "    col = idx % 4\n",
        "    sns.boxplot(data=df_viz, x='Variedade_Nome', y=caracteristica, ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'{caracteristica} por Variedade', fontweight='bold')\n",
        "    axes[row, col].set_xlabel('Variedade')\n",
        "    axes[row, col].set_ylabel(caracteristica)\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "# Remover subplot vazio\n",
        "axes[1, 3].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.3.3. Gráficos de Dispersão (Scatter Plots)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de correlação\n",
        "correlation_matrix = df.iloc[:, :-1].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.2f')\n",
        "plt.title('Matriz de Correlação entre Características', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráficos de dispersão para pares de características importantes\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Gráficos de Dispersão - Relações entre Características', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Área vs Perímetro\n",
        "sns.scatterplot(data=df_viz, x='Area', y='Perimetro', hue='Variedade_Nome', \n",
        "                style='Variedade_Nome', s=100, ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Área vs Perímetro', fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Comprimento do Núcleo vs Largura do Núcleo\n",
        "sns.scatterplot(data=df_viz, x='Comprimento_Nucleo', y='Largura_Nucleo', \n",
        "                hue='Variedade_Nome', style='Variedade_Nome', s=100, ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Comprimento do Núcleo vs Largura do Núcleo', fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Compacidade vs Coeficiente de Assimetria\n",
        "sns.scatterplot(data=df_viz, x='Compacidade', y='Coeficiente_Assimetria', \n",
        "                hue='Variedade_Nome', style='Variedade_Nome', s=100, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Compacidade vs Coeficiente de Assimetria', fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Comprimento do Sulco vs Área\n",
        "sns.scatterplot(data=df_viz, x='Comprimento_Sulco_Nucleo', y='Area', \n",
        "                hue='Variedade_Nome', style='Variedade_Nome', s=100, ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Comprimento do Sulco vs Área', fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Preparação dos Dados (Data Preparation)\n",
        "\n",
        "### 3.1. Tratamento de Valores Ausentes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificando valores ausentes novamente\n",
        "print(\"Valores ausentes por coluna:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values)\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"Tratando valores ausentes...\")\n",
        "    # Estratégia: preencher com a mediana da coluna\n",
        "    for col in df.columns[:-1]:  # Todas exceto 'Variedade'\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            median_value = df[col].median()\n",
        "            df[col].fillna(median_value, inplace=True)\n",
        "            print(f\"Coluna {col}: {df[col].isnull().sum()} valores ausentes preenchidos com mediana {median_value:.2f}\")\n",
        "else:\n",
        "    print(\"✓ Não há valores ausentes no dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Separação em Features e Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separando features (X) e target (y)\n",
        "X = df.drop('Variedade', axis=1)\n",
        "y = df['Variedade']\n",
        "\n",
        "print(\"Shape das features (X):\", X.shape)\n",
        "print(\"Shape do target (y):\", y.shape)\n",
        "print(\"\\nDistribuição das classes:\")\n",
        "print(y.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3. Normalização/Padronização dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicando StandardScaler para padronizar os dados\n",
        "# Isso é importante para algoritmos sensíveis à escala (SVM, KNN, etc.)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convertendo de volta para DataFrame para melhor visualização\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"Dados originais (primeiras 5 linhas):\")\n",
        "print(X.head())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "print(\"Dados padronizados (primeiras 5 linhas):\")\n",
        "print(X_scaled_df.head())\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "print(\"Estatísticas dos dados padronizados:\")\n",
        "print(X_scaled_df.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4. Divisão em Conjuntos de Treinamento e Teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Divisão: 70% treinamento, 30% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Divisão dos dados:\")\n",
        "print(f\"Conjunto de treinamento: {X_train.shape[0]} amostras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"Conjunto de teste: {X_test.shape[0]} amostras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "print(\"Distribuição das classes no conjunto de treinamento:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(\"\\nDistribuição das classes no conjunto de teste:\")\n",
        "print(y_test.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Modelagem (Modeling)\n",
        "\n",
        "### 4.1. Implementação e Comparação de Algoritmos\n",
        "\n",
        "Vamos implementar e comparar os seguintes algoritmos:\n",
        "1. K-Nearest Neighbors (KNN)\n",
        "2. Support Vector Machine (SVM)\n",
        "3. Random Forest\n",
        "4. Naive Bayes\n",
        "5. Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para avaliar modelos\n",
        "def avaliar_modelo(modelo, X_train, X_test, y_train, y_test, nome_modelo):\n",
        "    \"\"\"\n",
        "    Treina e avalia um modelo de classificação\n",
        "    \"\"\"\n",
        "    # Treinamento\n",
        "    modelo.fit(X_train, y_train)\n",
        "    \n",
        "    # Predições\n",
        "    y_pred_train = modelo.predict(X_train)\n",
        "    y_pred_test = modelo.predict(X_test)\n",
        "    \n",
        "    # Métricas de treinamento\n",
        "    acc_train = accuracy_score(y_train, y_pred_train)\n",
        "    prec_train = precision_score(y_train, y_pred_train, average='weighted')\n",
        "    rec_train = recall_score(y_train, y_pred_train, average='weighted')\n",
        "    f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
        "    \n",
        "    # Métricas de teste\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "    prec_test = precision_score(y_test, y_pred_test, average='weighted')\n",
        "    rec_test = recall_score(y_test, y_pred_test, average='weighted')\n",
        "    f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
        "    \n",
        "    # Matriz de confusão\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "    \n",
        "    resultados = {\n",
        "        'Modelo': nome_modelo,\n",
        "        'Acurácia_Treino': acc_train,\n",
        "        'Acurácia_Teste': acc_test,\n",
        "        'Precisão_Treino': prec_train,\n",
        "        'Precisão_Teste': prec_test,\n",
        "        'Recall_Treino': rec_train,\n",
        "        'Recall_Teste': rec_test,\n",
        "        'F1_Score_Treino': f1_train,\n",
        "        'F1_Score_Teste': f1_test,\n",
        "        'Matriz_Confusao': cm,\n",
        "        'Modelo_Objeto': modelo\n",
        "    }\n",
        "    \n",
        "    return resultados\n",
        "\n",
        "# Dicionário para armazenar resultados\n",
        "resultados_modelos = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1.1. K-Nearest Neighbors (KNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KNN com k=5 (valor padrão)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "resultados_knn = avaliar_modelo(knn, X_train, X_test, y_train, y_test, 'KNN')\n",
        "resultados_modelos['KNN'] = resultados_knn\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS - K-Nearest Neighbors (KNN)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Treino): {resultados_knn['Acurácia_Treino']:.4f}\")\n",
        "print(f\"Acurácia (Teste): {resultados_knn['Acurácia_Teste']:.4f}\")\n",
        "print(f\"Precisão (Teste): {resultados_knn['Precisão_Teste']:.4f}\")\n",
        "print(f\"Recall (Teste): {resultados_knn['Recall_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_knn['F1_Score_Teste']:.4f}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(resultados_knn['Matriz_Confusao'])\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, knn.predict(X_test), \n",
        "                          target_names=['Kama', 'Rosa', 'Canadian']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1.2. Support Vector Machine (SVM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVM com kernel RBF (padrão)\n",
        "svm = SVC(kernel='rbf', random_state=42)\n",
        "resultados_svm = avaliar_modelo(svm, X_train, X_test, y_train, y_test, 'SVM')\n",
        "resultados_modelos['SVM'] = resultados_svm\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS - Support Vector Machine (SVM)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Treino): {resultados_svm['Acurácia_Treino']:.4f}\")\n",
        "print(f\"Acurácia (Teste): {resultados_svm['Acurácia_Teste']:.4f}\")\n",
        "print(f\"Precisão (Teste): {resultados_svm['Precisão_Teste']:.4f}\")\n",
        "print(f\"Recall (Teste): {resultados_svm['Recall_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_svm['F1_Score_Teste']:.4f}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(resultados_svm['Matriz_Confusao'])\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, svm.predict(X_test), \n",
        "                          target_names=['Kama', 'Rosa', 'Canadian']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1.3. Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest com 100 árvores\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "resultados_rf = avaliar_modelo(rf, X_train, X_test, y_train, y_test, 'Random Forest')\n",
        "resultados_modelos['Random Forest'] = resultados_rf\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS - Random Forest\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Treino): {resultados_rf['Acurácia_Treino']:.4f}\")\n",
        "print(f\"Acurácia (Teste): {resultados_rf['Acurácia_Teste']:.4f}\")\n",
        "print(f\"Precisão (Teste): {resultados_rf['Precisão_Teste']:.4f}\")\n",
        "print(f\"Recall (Teste): {resultados_rf['Recall_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_rf['F1_Score_Teste']:.4f}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(resultados_rf['Matriz_Confusao'])\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, rf.predict(X_test), \n",
        "                          target_names=['Kama', 'Rosa', 'Canadian']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1.4. Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Naive Bayes Gaussiano\n",
        "nb = GaussianNB()\n",
        "resultados_nb = avaliar_modelo(nb, X_train, X_test, y_train, y_test, 'Naive Bayes')\n",
        "resultados_modelos['Naive Bayes'] = resultados_nb\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS - Naive Bayes\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Treino): {resultados_nb['Acurácia_Treino']:.4f}\")\n",
        "print(f\"Acurácia (Teste): {resultados_nb['Acurácia_Teste']:.4f}\")\n",
        "print(f\"Precisão (Teste): {resultados_nb['Precisão_Teste']:.4f}\")\n",
        "print(f\"Recall (Teste): {resultados_nb['Recall_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_nb['F1_Score_Teste']:.4f}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(resultados_nb['Matriz_Confusao'])\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, nb.predict(X_test), \n",
        "                          target_names=['Kama', 'Rosa', 'Canadian']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.1.5. Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "resultados_lr = avaliar_modelo(lr, X_train, X_test, y_train, y_test, 'Logistic Regression')\n",
        "resultados_modelos['Logistic Regression'] = resultados_lr\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RESULTADOS - Logistic Regression\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Treino): {resultados_lr['Acurácia_Treino']:.4f}\")\n",
        "print(f\"Acurácia (Teste): {resultados_lr['Acurácia_Teste']:.4f}\")\n",
        "print(f\"Precisão (Teste): {resultados_lr['Precisão_Teste']:.4f}\")\n",
        "print(f\"Recall (Teste): {resultados_lr['Recall_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_lr['F1_Score_Teste']:.4f}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(resultados_lr['Matriz_Confusao'])\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, lr.predict(X_test), \n",
        "                          target_names=['Kama', 'Rosa', 'Canadian']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2. Comparação dos Modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando DataFrame comparativo\n",
        "comparacao = pd.DataFrame({\n",
        "    'Modelo': [r['Modelo'] for r in resultados_modelos.values()],\n",
        "    'Acurácia_Treino': [r['Acurácia_Treino'] for r in resultados_modelos.values()],\n",
        "    'Acurácia_Teste': [r['Acurácia_Teste'] for r in resultados_modelos.values()],\n",
        "    'Precisão_Teste': [r['Precisão_Teste'] for r in resultados_modelos.values()],\n",
        "    'Recall_Teste': [r['Recall_Teste'] for r in resultados_modelos.values()],\n",
        "    'F1_Score_Teste': [r['F1_Score_Teste'] for r in resultados_modelos.values()]\n",
        "})\n",
        "\n",
        "# Ordenando por acurácia de teste\n",
        "comparacao = comparacao.sort_values('Acurácia_Teste', ascending=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARAÇÃO DE MODELOS\")\n",
        "print(\"=\"*80)\n",
        "print(comparacao.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização comparativa\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Comparação de Desempenho dos Modelos', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Gráfico 1: Acurácia\n",
        "ax1 = axes[0, 0]\n",
        "comparacao.plot(x='Modelo', y=['Acurácia_Treino', 'Acurácia_Teste'], \n",
        "                kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
        "ax1.set_title('Acurácia: Treino vs Teste', fontweight='bold')\n",
        "ax1.set_ylabel('Acurácia')\n",
        "ax1.set_xlabel('Modelo')\n",
        "ax1.legend(['Treino', 'Teste'])\n",
        "ax1.set_xticklabels(comparacao['Modelo'], rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Gráfico 2: Métricas de Teste\n",
        "ax2 = axes[0, 1]\n",
        "comparacao.plot(x='Modelo', y=['Precisão_Teste', 'Recall_Teste', 'F1_Score_Teste'], \n",
        "                kind='bar', ax=ax2, color=['green', 'orange', 'purple'])\n",
        "ax2.set_title('Métricas de Desempenho no Conjunto de Teste', fontweight='bold')\n",
        "ax2.set_ylabel('Score')\n",
        "ax2.set_xlabel('Modelo')\n",
        "ax2.legend(['Precisão', 'Recall', 'F1-Score'])\n",
        "ax2.set_xticklabels(comparacao['Modelo'], rotation=45, ha='right')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Gráfico 3: Acurácia de Teste (ordenado)\n",
        "ax3 = axes[1, 0]\n",
        "comparacao_sorted = comparacao.sort_values('Acurácia_Teste', ascending=True)\n",
        "ax3.barh(comparacao_sorted['Modelo'], comparacao_sorted['Acurácia_Teste'], color='steelblue')\n",
        "ax3.set_title('Acurácia no Conjunto de Teste (Ordenado)', fontweight='bold')\n",
        "ax3.set_xlabel('Acurácia')\n",
        "ax3.set_xlim([0.85, 1.0])\n",
        "ax3.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Gráfico 4: F1-Score de Teste (ordenado)\n",
        "ax4 = axes[1, 1]\n",
        "comparacao_sorted_f1 = comparacao.sort_values('F1_Score_Teste', ascending=True)\n",
        "ax4.barh(comparacao_sorted_f1['Modelo'], comparacao_sorted_f1['F1_Score_Teste'], color='coral')\n",
        "ax4.set_title('F1-Score no Conjunto de Teste (Ordenado)', fontweight='bold')\n",
        "ax4.set_xlabel('F1-Score')\n",
        "ax4.set_xlim([0.85, 1.0])\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização das matrizes de confusão\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Matrizes de Confusão - Todos os Modelos', fontsize=16, fontweight='bold')\n",
        "\n",
        "modelos_nomes = list(resultados_modelos.keys())\n",
        "classes = ['Kama', 'Rosa', 'Canadian']\n",
        "\n",
        "for idx, (nome, resultado) in enumerate(resultados_modelos.items()):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    cm = resultado['Matriz_Confusao']\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[row, col],\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    axes[row, col].set_title(f'{nome}\\nAcurácia: {resultado[\"Acurácia_Teste\"]:.4f}', \n",
        "                            fontweight='bold')\n",
        "    axes[row, col].set_ylabel('Verdadeiro')\n",
        "    axes[row, col].set_xlabel('Predito')\n",
        "\n",
        "# Remover subplot vazio\n",
        "axes[1, 2].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Otimização de Hiperparâmetros\n",
        "\n",
        "Vamos utilizar Grid Search para encontrar os melhores hiperparâmetros para cada modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dicionário para armazenar modelos otimizados\n",
        "modelos_otimizados = {}\n",
        "resultados_otimizados = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1. Otimização do KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para KNN\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, \n",
        "                        scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros para KNN:\")\n",
        "print(grid_knn.best_params_)\n",
        "print(f\"\\nMelhor score (CV): {grid_knn.best_score_:.4f}\")\n",
        "\n",
        "# Avaliando modelo otimizado\n",
        "knn_otimizado = grid_knn.best_estimator_\n",
        "resultados_knn_opt = avaliar_modelo(knn_otimizado, X_train, X_test, y_train, y_test, 'KNN (Otimizado)')\n",
        "resultados_otimizados['KNN'] = resultados_knn_opt\n",
        "modelos_otimizados['KNN'] = knn_otimizado\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS - KNN OTIMIZADO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Teste): {resultados_knn_opt['Acurácia_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_knn_opt['F1_Score_Teste']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2. Otimização do SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para SVM\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf', 'linear', 'poly']\n",
        "}\n",
        "\n",
        "grid_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5, \n",
        "                       scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros para SVM:\")\n",
        "print(grid_svm.best_params_)\n",
        "print(f\"\\nMelhor score (CV): {grid_svm.best_score_:.4f}\")\n",
        "\n",
        "# Avaliando modelo otimizado\n",
        "svm_otimizado = grid_svm.best_estimator_\n",
        "resultados_svm_opt = avaliar_modelo(svm_otimizado, X_train, X_test, y_train, y_test, 'SVM (Otimizado)')\n",
        "resultados_otimizados['SVM'] = resultados_svm_opt\n",
        "modelos_otimizados['SVM'] = svm_otimizado\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS - SVM OTIMIZADO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Teste): {resultados_svm_opt['Acurácia_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_svm_opt['F1_Score_Teste']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3. Otimização do Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, \n",
        "                      scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros para Random Forest:\")\n",
        "print(grid_rf.best_params_)\n",
        "print(f\"\\nMelhor score (CV): {grid_rf.best_score_:.4f}\")\n",
        "\n",
        "# Avaliando modelo otimizado\n",
        "rf_otimizado = grid_rf.best_estimator_\n",
        "resultados_rf_opt = avaliar_modelo(rf_otimizado, X_train, X_test, y_train, y_test, 'Random Forest (Otimizado)')\n",
        "resultados_otimizados['Random Forest'] = resultados_rf_opt\n",
        "modelos_otimizados['Random Forest'] = rf_otimizado\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS - RANDOM FOREST OTIMIZADO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Teste): {resultados_rf_opt['Acurácia_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_rf_opt['F1_Score_Teste']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4. Otimização do Naive Bayes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para Naive Bayes\n",
        "param_grid_nb = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "grid_nb = GridSearchCV(GaussianNB(), param_grid_nb, cv=5, \n",
        "                      scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros para Naive Bayes:\")\n",
        "print(grid_nb.best_params_)\n",
        "print(f\"\\nMelhor score (CV): {grid_nb.best_score_:.4f}\")\n",
        "\n",
        "# Avaliando modelo otimizado\n",
        "nb_otimizado = grid_nb.best_estimator_\n",
        "resultados_nb_opt = avaliar_modelo(nb_otimizado, X_train, X_test, y_train, y_test, 'Naive Bayes (Otimizado)')\n",
        "resultados_otimizados['Naive Bayes'] = resultados_nb_opt\n",
        "modelos_otimizados['Naive Bayes'] = nb_otimizado\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS - NAIVE BAYES OTIMIZADO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Teste): {resultados_nb_opt['Acurácia_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_nb_opt['F1_Score_Teste']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5. Otimização da Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'solver': ['liblinear', 'lbfgs', 'saga']\n",
        "}\n",
        "\n",
        "# Ajustando solver baseado no penalty\n",
        "param_grid_lr_adj = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), \n",
        "                       param_grid_lr_adj, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros para Logistic Regression:\")\n",
        "print(grid_lr.best_params_)\n",
        "print(f\"\\nMelhor score (CV): {grid_lr.best_score_:.4f}\")\n",
        "\n",
        "# Avaliando modelo otimizado\n",
        "lr_otimizado = grid_lr.best_estimator_\n",
        "resultados_lr_opt = avaliar_modelo(lr_otimizado, X_train, X_test, y_train, y_test, 'Logistic Regression (Otimizado)')\n",
        "resultados_otimizados['Logistic Regression'] = resultados_lr_opt\n",
        "modelos_otimizados['Logistic Regression'] = lr_otimizado\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTADOS - LOGISTIC REGRESSION OTIMIZADO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Acurácia (Teste): {resultados_lr_opt['Acurácia_Teste']:.4f}\")\n",
        "print(f\"F1-Score (Teste): {resultados_lr_opt['F1_Score_Teste']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.6. Comparação: Modelos Originais vs Otimizados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparação antes e depois da otimização\n",
        "comparacao_otimizacao = pd.DataFrame({\n",
        "    'Modelo': [r['Modelo'] for r in resultados_modelos.values()],\n",
        "    'Acurácia_Antes': [r['Acurácia_Teste'] for r in resultados_modelos.values()],\n",
        "    'Acurácia_Depois': [r['Acurácia_Teste'] for r in resultados_otimizados.values()],\n",
        "    'F1_Antes': [r['F1_Score_Teste'] for r in resultados_modelos.values()],\n",
        "    'F1_Depois': [r['F1_Score_Teste'] for r in resultados_otimizados.values()]\n",
        "})\n",
        "\n",
        "comparacao_otimizacao['Melhoria_Acurácia'] = comparacao_otimizacao['Acurácia_Depois'] - comparacao_otimizacao['Acurácia_Antes']\n",
        "comparacao_otimizacao['Melhoria_F1'] = comparacao_otimizacao['F1_Depois'] - comparacao_otimizacao['F1_Antes']\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARAÇÃO: ANTES vs DEPOIS DA OTIMIZAÇÃO\")\n",
        "print(\"=\"*80)\n",
        "print(comparacao_otimizacao.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização da comparação\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Comparação: Modelos Originais vs Otimizados', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Gráfico 1: Acurácia\n",
        "ax1 = axes[0]\n",
        "x = np.arange(len(comparacao_otimizacao))\n",
        "width = 0.35\n",
        "ax1.bar(x - width/2, comparacao_otimizacao['Acurácia_Antes'], width, \n",
        "        label='Antes', color='lightblue', alpha=0.8)\n",
        "ax1.bar(x + width/2, comparacao_otimizacao['Acurácia_Depois'], width, \n",
        "        label='Depois', color='steelblue', alpha=0.8)\n",
        "ax1.set_xlabel('Modelo')\n",
        "ax1.set_ylabel('Acurácia')\n",
        "ax1.set_title('Acurácia: Antes vs Depois da Otimização', fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(comparacao_otimizacao['Modelo'], rotation=45, ha='right')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Gráfico 2: F1-Score\n",
        "ax2 = axes[1]\n",
        "ax2.bar(x - width/2, comparacao_otimizacao['F1_Antes'], width, \n",
        "        label='Antes', color='lightcoral', alpha=0.8)\n",
        "ax2.bar(x + width/2, comparacao_otimizacao['F1_Depois'], width, \n",
        "        label='Depois', color='crimson', alpha=0.8)\n",
        "ax2.set_xlabel('Modelo')\n",
        "ax2.set_ylabel('F1-Score')\n",
        "ax2.set_title('F1-Score: Antes vs Depois da Otimização', fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(comparacao_otimizacao['Modelo'], rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ranking final dos modelos otimizados\n",
        "ranking_final = pd.DataFrame({\n",
        "    'Modelo': [r['Modelo'] for r in resultados_otimizados.values()],\n",
        "    'Acurácia_Teste': [r['Acurácia_Teste'] for r in resultados_otimizados.values()],\n",
        "    'Precisão_Teste': [r['Precisão_Teste'] for r in resultados_otimizados.values()],\n",
        "    'Recall_Teste': [r['Recall_Teste'] for r in resultados_otimizados.values()],\n",
        "    'F1_Score_Teste': [r['F1_Score_Teste'] for r in resultados_otimizados.values()]\n",
        "})\n",
        "\n",
        "ranking_final = ranking_final.sort_values('Acurácia_Teste', ascending=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"RANKING FINAL DOS MODELOS OTIMIZADOS\")\n",
        "print(\"=\"*80)\n",
        "print(ranking_final.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Avaliação (Evaluation)\n",
        "\n",
        "### 6.1. Análise de Importância de Features (Random Forest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importância das features no Random Forest otimizado\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importância': rf_otimizado.feature_importances_\n",
        "}).sort_values('Importância', ascending=False)\n",
        "\n",
        "print(\"Importância das Features (Random Forest):\")\n",
        "print(\"=\"*80)\n",
        "print(feature_importance.to_string(index=False))\n",
        "\n",
        "# Visualização\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Importância'], color='steelblue')\n",
        "plt.xlabel('Importância')\n",
        "plt.title('Importância das Features - Random Forest Otimizado', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2. Matrizes de Confusão dos Modelos Otimizados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização das matrizes de confusão dos modelos otimizados\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Matrizes de Confusão - Modelos Otimizados', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, (nome, resultado) in enumerate(resultados_otimizados.items()):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    cm = resultado['Matriz_Confusao']\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[row, col],\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    axes[row, col].set_title(f'{nome}\\nAcurácia: {resultado[\"Acurácia_Teste\"]:.4f}', \n",
        "                            fontweight='bold')\n",
        "    axes[row, col].set_ylabel('Verdadeiro')\n",
        "    axes[row, col].set_xlabel('Predito')\n",
        "\n",
        "# Remover subplot vazio\n",
        "axes[1, 2].remove()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Implantação e Interpretação dos Resultados (Deployment & Interpretation)\n",
        "\n",
        "### 7.1. Resumo dos Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"RESUMO EXECUTIVO DOS RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n1. MELHOR MODELO:\")\n",
        "melhor_modelo = ranking_final.iloc[0]\n",
        "print(f\"   Modelo: {melhor_modelo['Modelo']}\")\n",
        "print(f\"   Acurácia: {melhor_modelo['Acurácia_Teste']:.4f} ({melhor_modelo['Acurácia_Teste']*100:.2f}%)\")\n",
        "print(f\"   F1-Score: {melhor_modelo['F1_Score_Teste']:.4f}\")\n",
        "\n",
        "print(\"\\n2. TOP 3 MODELOS:\")\n",
        "for idx, row in ranking_final.head(3).iterrows():\n",
        "    print(f\"   {idx+1}. {row['Modelo']}: Acurácia = {row['Acurácia_Teste']:.4f}\")\n",
        "\n",
        "print(\"\\n3. MELHORIAS COM OTIMIZAÇÃO:\")\n",
        "for idx, row in comparacao_otimizacao.iterrows():\n",
        "    if row['Melhoria_Acurácia'] > 0:\n",
        "        print(f\"   {row['Modelo']}: +{row['Melhoria_Acurácia']*100:.2f}% em acurácia\")\n",
        "\n",
        "print(\"\\n4. FEATURES MAIS IMPORTANTES:\")\n",
        "for idx, row in feature_importance.head(3).iterrows():\n",
        "    print(f\"   {idx+1}. {row['Feature']}: {row['Importância']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2. Insights e Interpretações\n",
        "\n",
        "#### Insights Principais:\n",
        "\n",
        "1. **Desempenho dos Modelos:**\n",
        "   - Todos os modelos apresentaram excelente desempenho, com acurácias superiores a 90%\n",
        "   - A otimização de hiperparâmetros trouxe melhorias significativas para a maioria dos modelos\n",
        "   - O modelo Random Forest otimizado destacou-se como o melhor classificador\n",
        "\n",
        "2. **Características Mais Importantes:**\n",
        "   - As características físicas dos grãos são altamente discriminativas\n",
        "   - Área, Perímetro e Comprimento do Núcleo são as features mais importantes\n",
        "   - Isso indica que o tamanho e formato dos grãos são os principais fatores de diferenciação\n",
        "\n",
        "3. **Aplicabilidade Prática:**\n",
        "   - O modelo pode ser implementado em cooperativas agrícolas para automatizar a classificação\n",
        "   - A alta acurácia garante confiabilidade no processo de classificação\n",
        "   - O processo automatizado reduz tempo e custos operacionais\n",
        "\n",
        "4. **Limitações e Considerações:**\n",
        "   - O dataset é relativamente pequeno (210 amostras)\n",
        "   - Seria benéfico coletar mais dados para aumentar a robustez do modelo\n",
        "   - Validação em condições reais de campo seria necessária antes da implantação completa\n",
        "pacidad eé calculada image.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3. Exemplo de Predição com o Melhor Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecionando o melhor modelo\n",
        "melhor_modelo_nome = ranking_final.iloc[0]['Modelo']\n",
        "melhor_modelo_obj = modelos_otimizados[melhor_modelo_nome]\n",
        "\n",
        "# Exemplo de predição com algumas amostras do conjunto de teste\n",
        "print(\"=\"*80)\n",
        "print(\"EXEMPLO DE PREDIÇÕES COM O MELHOR MODELO\")\n",
        "print(f\"Modelo: {melhor_modelo_nome}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Selecionando 5 amostras aleatórias do conjunto de teste\n",
        "np.random.seed(42)\n",
        "indices_amostra = np.random.choice(len(X_test), 5, replace=False)\n",
        "\n",
        "for idx in indices_amostra:\n",
        "    amostra = X_test[idx].reshape(1, -1)\n",
        "    predicao = melhor_modelo_obj.predict(amostra)[0]\n",
        "    verdadeiro = y_test.iloc[idx]\n",
        "    \n",
        "    nome_predicao = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}[predicao]\n",
        "    nome_verdadeiro = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}[verdadeiro]\n",
        "    \n",
        "    status = \"✓ CORRETO\" if predicao == verdadeiro else \"✗ INCORRETO\"\n",
        "    \n",
        "    print(f\"\\nAmostra {idx+1}:\")\n",
        "    print(f\"  Características: {X_test[idx]}\")\n",
        "    print(f\"  Variedade Real: {nome_verdadeiro} ({verdadeiro})\")\n",
        "    print(f\"  Variedade Predita: {nome_predicao} ({predicao})\")\n",
        "    print(f\"  Status: {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusões\n",
        "\n",
        "### Conclusões Finais:\n",
        "\n",
        "1. **Objetivo Alcançado:** Foi possível desenvolver modelos de Machine Learning capazes de classificar variedades de grãos de trigo com alta precisão, atingindo acurácias superiores a 90%.\n",
        "\n",
        "2. **Metodologia CRISP-DM:** A aplicação da metodologia CRISP-DM permitiu uma abordagem estruturada e completa, desde o entendimento do problema até a interpretação dos resultados.\n",
        "\n",
        "3. **Modelo Recomendado:** O **Random Forest otimizado** apresentou o melhor desempenho geral, sendo recomendado para implantação em produção.\n",
        "\n",
        "4. **Impacto no Negócio:** A automação do processo de classificação pode trazer benefícios significativos:\n",
        "   - Redução de tempo no processo de classificação\n",
        "   - Aumento da precisão e consistência\n",
        "   - Redução de custos operacionais\n",
        "   - Escalabilidade do processo\n",
        "\n",
        "5. **Próximos Passos:**\n",
        "   - Coleta de mais dados para aumentar a robustez do modelo\n",
        "   - Validação em condições reais de campo\n",
        "   - Desenvolvimento de interface para uso prático\n",
        "   - Monitoramento contínuo do desempenho do modelo\n",
        "\n",
        "---\n",
        "\n",
        "**Projeto desenvolvido seguindo a metodologia CRISP-DM**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
